{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment number = 2\n",
    "### Name = Varun Vashishtha\n",
    "### Roll number = 2022201061"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the SIFT detector and descriptor. Compute cluster centers for the Bag-of-Visual-Words approach. Represent the images as histograms (of visual words) and train a linear SVM model for 10-way classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from torchvision import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import gen_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading MNIST dataset\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True)\n",
    "training_image_dataset = mnist_train.data.numpy()\n",
    "training_labels = mnist_train.targets.numpy()\n",
    "testing_images = mnist_test.data.numpy()\n",
    "testing_labels = mnist_test.targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Extracting SIFT descriptors\n",
    "def extract_sift_descriptors(image):\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints,descriptors\n",
    "\n",
    "# Extracting SIFT descriptors\n",
    "training_descriptors = []\n",
    "for image in training_image_dataset:\n",
    "    keypoints,descriptors = extract_sift_descriptors(image.astype(np.uint8))\n",
    "    if descriptors is not None:\n",
    "        training_descriptors.append(descriptors)\n",
    "\n",
    "# Stack all descriptors into a single array\n",
    "training_descriptors = np.vstack(training_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469496, 128)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33.,   0.,   0.,   0.,   0.,   0.,   0.,  10., 144.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  79.,  94.,   1.,   3.,  20.,  82.,  70.,\n",
       "         3.,  28.,   0.,   0.,   6.,  22.,  60.,  97.,  79.,  20.,  70.,\n",
       "         3.,   0.,   0.,   0.,   0.,   0.,  10., 144.,  40.,  19.,  13.,\n",
       "         0.,   0.,   0.,  43.,  66.,  13.,  89., 144.,  13.,  15.,   1.,\n",
       "         7.,   0.,   0., 144., 124.,   7.,  24.,  21.,   2.,  33.,  21.,\n",
       "         1.,   0.,   0.,   0.,   0.,   1.,  92., 144., 112.,  24.,   0.,\n",
       "         0.,   0.,   1.,   5.,  19., 125., 144.,   4.,   0.,   0.,   0.,\n",
       "         0.,   0.,  64.,  71.,   1.,   0.,   0.,   0.,   0.,   4.,   1.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  15.,  30.,   2.,   0.,   0.,\n",
       "         0.,   0.,   0.,   1.,  26.,  15.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   1.,   4.,   0.,   0.,   0.,   0.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_descriptors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=10, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster descriptors to get visual words\n",
    "kmeans_classifier = KMeans(n_clusters=10, random_state=42)\n",
    "kmeans_classifier.fit(training_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_classifier.cluster_centers_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_visual_word_histogram(image, kmeans_classifier):\n",
    "    keypoints,descriptors = extract_sift_descriptors(image.astype(np.uint8))\n",
    "    if descriptors is None:\n",
    "        return np.zeros(len(kmeans_classifier.cluster_centers_))\n",
    "    labels = kmeans_classifier.predict(descriptors)\n",
    "    hist, _ = np.histogram(labels, bins=range(len(kmeans_classifier.cluster_centers_)+1),density=True)\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_visual_word_histogram(image, kmeans_classifier):\n",
    "    keypoints, descriptors = extract_sift_descriptors(image.astype(np.uint8))\n",
    "\n",
    "    if descriptors is None:\n",
    "        return np.zeros(len(kmeans_classifier.cluster_centers_))\n",
    "\n",
    "    batch_size = 1000\n",
    "    batches = gen_batches(len(descriptors), batch_size)\n",
    "    hist = np.zeros(len(kmeans_classifier.cluster_centers_))\n",
    "\n",
    "    for batch in batches:\n",
    "        batch_descriptors = descriptors[batch]\n",
    "        labels = kmeans_classifier.predict(batch_descriptors)\n",
    "        hist_batch, _ = np.histogram(labels, bins=range(len(kmeans_classifier.cluster_centers_) + 1), density=True)\n",
    "        hist += hist_batch * (batch.stop - batch.start) / len(descriptors)  \n",
    "\n",
    "    return hist\n",
    "\n",
    "\n",
    "training_histogram = []\n",
    "for image in training_image_dataset:\n",
    "    hist = compute_visual_word_histo(image, kmeans_classifier)\n",
    "    training_histogram.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_histogram = np.array(training_histogram)\n",
    "\n",
    "training_histogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0. , 0. , 0.2 , 0. , 0.2 , 0. , 0. , 0.6 , 0. , 0. ])\n"
     ]
    }
   ],
   "source": [
    "training_histogram[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels = np.array(training_labels)\n",
    "\n",
    "training_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "support_vector_machine_classifier = SVC(kernel='linear', random_state=42)\n",
    "support_vector_machine_classifier.fit(training_histogram, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3996\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(testing_images, testing_labels, kmeans_classifier, svm_classifier):\n",
    "    test_histograms = [compute_visual_word_histogram(image, kmeans_classifier) for image in testing_images]\n",
    "    predictions = svm_classifier.predict(test_histograms)\n",
    "    accuracy = accuracy_score(testing_labels, predictions)\n",
    "    return accuracy\n",
    "\n",
    "test_accuracy = evaluate_model(testing_images, testing_labels, kmeans_classifier, svm)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping everything else constant, plot how classification accuracy changes as you sweep across 6 different values for the number of clusters. Please decide what numbers are meaningful for this question. Explain the trends in classification accuracy that you observe.\n",
    "\n",
    "\n",
    "In the SIFT-BoVW-SVM approach, the number of clusters (or visual words) used in the Bag of Visual Words (BoVW) model can affect the accuracy of the model. Increasing the number of clusters can lead to an increase in accuracy up to a certain point due to the following reasons:\n",
    "\n",
    "Better Representation: With more clusters, the BoVW model can represent the visual features of the images more accurately. This can lead to better discrimination between different classes.\n",
    "\n",
    "Reduced Ambiguity: A higher number of clusters can reduce ambiguity in feature representation. This means that each visual word is more specific to certain types of features, making it easier for the SVM classifier to distinguish between classes.\n",
    "\n",
    "Improved Generalization: Increasing the number of clusters can lead to a more detailed representation of the visual features, which can help the model generalize better to unseen data.\n",
    "\n",
    "However, increasing the number of clusters beyond a certain point can lead to overfitting, where the model becomes too specialized on the training data and performs poorly on unseen data. Therefore, there is a trade-off between the number of clusters and model performance, and finding the optimal number of clusters is important for achieving the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def sift_accuracy(num_clusters = 2, training_image_dataset, testing_images, training_labels, testing_labels):\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    def extract_sift_descriptor(image, sift):\n",
    "        keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "        return keypoints, descriptors\n",
    "\n",
    "    training_descriptors = []\n",
    "    for image in training_image_dataset:\n",
    "        keypoints, descriptors = extract_sift_descriptor(image.astype(np.uint8), sift)\n",
    "        if descriptors is not None:\n",
    "            training_descriptors.append(descriptors)\n",
    "\n",
    "    training_descriptors = np.vstack(training_descriptors)\n",
    "\n",
    "    kmeans_classifier = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans_classifier.fit(training_descriptors)\n",
    "\n",
    "    num_samples = 12000\n",
    "    try:\n",
    "        selected_indices = np.random.choice(len(training_image_dataset), num_samples, replace=False)\n",
    "    except ValueError:\n",
    "        selected_indices = np.arange(len(training_image_dataset))\n",
    "    \n",
    "    selected_images = training_image_dataset[selected_indices]\n",
    "    selected_labels = training_labels[selected_indices]\n",
    "\n",
    "    training_histogramgrams = []\n",
    "    for image in selected_images:\n",
    "        hist = compute_visual_word_histogram(image, kmeans_classifier)\n",
    "        training_histogramgrams.append(hist)\n",
    "\n",
    "    training_histogramgrams = np.array(training_histogramgrams)\n",
    "    selected_labels = np.array(selected_labels)\n",
    "\n",
    "    support_vector_machine_classifier = SVC(kernel='linear', random_state=42)\n",
    "    support_vector_machine_classifier.fit(training_histogramgrams, selected_labels)\n",
    "    test_accuracy = evaluate_model(testing_images[:5000], testing_labels[:5000], kmeans_classifier, svm)\n",
    "    print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.1848\n"
     ]
    }
   ],
   "source": [
    "sift_accuracy(num_clusters = 2, training_image_dataset = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3086\n"
     ]
    }
   ],
   "source": [
    "sift_accuracy(num_clusters = 5, training_image_dataset = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.376\n"
     ]
    }
   ],
   "source": [
    "sift_accuracy(num_clusters = 10, training_image_dataset = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.473\n"
     ]
    }
   ],
   "source": [
    "sift_accuracy(num_clusters = 20,training_image_dataset = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6112\n"
     ]
    }
   ],
   "source": [
    "sift_accuracy(num_clusters = 50,training_image_dataset = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100 CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6692\n"
     ]
    }
   ],
   "source": [
    "sift_accuracy(num_clusters = 100, training_image_dataset = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the results for 6 different hyperparameter settings. You may play with the SIFT detector or descriptor and the linear SVM. Keep the number of clusters constant based on the answer to the previous question. Explain the trends in classification accuracy that you observe\n",
    "\n",
    "As the contrast_threshold, edge_threshold, sigma values increased the accuracy increased going from 65 to alomst 70%\n",
    "\n",
    "\n",
    "Also making the kernel complex also helped in capturing the complex information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_parameter_accuracy(num_clusters, contrast_threshold, edge_threshold, sigma, svm_kernel, training_images, testing_images, training_labels, testing_labels):\n",
    "    sift = cv2.SIFT_create(contrastThreshold=contrast_threshold, edgeThreshold=edge_threshold, sigma=sigma)\n",
    "\n",
    "    def extract_sift(image, sift_instance):\n",
    "        keypoints, descriptors = sift_instance.detectAndCompute(image, None)\n",
    "        return keypoints, descriptors\n",
    "\n",
    "    training_descriptors = []\n",
    "    for image in training_images:\n",
    "        keypoints, descriptors = extract_sift(image.astype(np.uint8), sift)\n",
    "        if descriptors is not None:\n",
    "            training_descriptors.append(descriptors)\n",
    "\n",
    "    training_descriptors = np.vstack(training_descriptors)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(training_descriptors)\n",
    "\n",
    "    num_samples = 12000\n",
    "    selected_indices = np.random.choice(len(training_images), num_samples, replace=False)\n",
    "    selected_images = training_images[selected_indices]\n",
    "    selected_labels = training_labels[selected_indices]\n",
    "\n",
    "    training_histogramgrams = []\n",
    "    for image in selected_images:\n",
    "        hist = compute_histogram(image, kmeans)\n",
    "        training_histogramgrams.append(hist)\n",
    "\n",
    "    training_histogramgrams = np.array(training_histogramgrams)\n",
    "    selected_labels = np.array(selected_labels)\n",
    "\n",
    "    svm_classifier = SVC(kernel=svm_kernel, random_state=42)\n",
    "    svm_classifier.fit(training_histogramgrams, selected_labels)\n",
    "    test_accuracy = evaluate_accuracy(testing_images, testing_labels, kmeans, svm_classifier)\n",
    "    print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6565\n"
     ]
    }
   ],
   "source": [
    "sift_parameter_accuracy(num_clusters=50, contrast_threshold = 0.04, edge_threshold = 10, sigma=1.5, svm_kernel = 'linear', training_images = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6656\n"
     ]
    }
   ],
   "source": [
    "sift_parameter_accuracy(num_clusters=50, contrast_threshold = 0.04, edge_threshold = 10, sigma=1.5, svm_kernel = 'poly', training_images = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radial basis function kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6843\n"
     ]
    }
   ],
   "source": [
    "sift_parameter_accuracy(num_clusters=50, contrast_threshold = 0.04, edge_threshold = 10, sigma=1.5, svm_kernel = 'rbf', training_images = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6617\n"
     ]
    }
   ],
   "source": [
    "sift_parameter_accuracy(num_clusters=50, contrast_threshold = 0.06, edge_threshold = 15, sigma=2.0, svm_kernel = 'sigmoid', training_images = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6755\n"
     ]
    }
   ],
   "source": [
    "sift_parameter_accuracy(num_clusters=50,  contrast_threshold = 0.06, edge_threshold = 15, sigma=2.0, svm_kernel = 'poly', training_images = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6925\n"
     ]
    }
   ],
   "source": [
    "sift_parameter_accuracy(num_clusters=50, contrast_threshold = 0.06, edge_threshold = 15, sigma=2.0, svm_kernel = 'rbf', training_images = training_image_dataset, testing_images = testing_images, training_labels = training_labels, testing_labels = testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenges : \n",
    "\n",
    "1) Knowing all the knitty-gritty of SIFT and then segregating and making of clusters.\n",
    "\n",
    "\n",
    "2) Playing with hyperparameters and get to know the reasoning behind the changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
